## Chat Completions (Single-turn tasks) So far, we have used the **Chat Completions endpoint** to do tasks like:- Generating text- Editing or rewriting text- Classifying text (for example, sentiment analysis)
# These are called **single-turn tasks**.That means:- We send **one input**- The model gives **one output**### Example:**User:**> “Write a short paragraph about Python.”**Assistant:**> “Python is a popular programming language…”Here, there is only **one question and one answer**.

## Chat Completions (Multi-turn conversations)Chat Completion models can also handle **multi-turn conversations**.This means the model can **remember previous messages** and respond based on them.### Example:**User:**> “Explain Python in one line.”**Assistant:**> “Python is an easy-to-read programming language.”**User (next message):**> “Give an example.”Now the model understands the context and replies accordingly.

## Roles in Chat ModelsRoles are **the core idea** behind how chat models work.There are **three main roles**:
### System role- Used to **control the behavior** of the assistant- Usually written by the **developer**- Tells the model *who it is* and *how it should respond*### Example:> “You are a polite and helpful customer support assistant.”Now the model will reply politely.
### User role- This is the **question or instruction** from the user### Example:> “My order is delayed. What should I do?”
### Assistant role- This is the **response generated by the model**- We can also manually add assistant messages as **examples** to guide the model### Example:We can show the model an example answer so it learns the style we want.> Assistant: “I’m sorry for the inconvenience. I’ll help you right away.”

## Prompt Setup with Multiple RolesTo add more control, we include **multiple messages** in the messages list.Usually, we start with a **system message**, then add a **user message**.### Example:**System message:**> “You are a Python tutor who explains concepts in simple and short sentences.”**User message:**> “What is a list in Python?”This tells the model *how* to explain before answering the question.

## The ResponseWhen we check the output, we notice something important:✅ The assistant follows the **system message**✅ It gives a **short and simple explanation**, just as instructed### Example response:> “A list in Python is a collection of items stored in one variable.”Only **one clear sentence**, because the system message asked for concise answers.

## Mitigating MisuseOne big challenge with AI systems is **misuse**.### Example problem:Imagine we build a chatbot to help students study **finance exams**.We do **NOT** want it to:- Give real investment advice- Suggest buying specific stocks- Risk the user’s moneyThis is where **system messages as guardrails** help us.

## Using System Messages as GuardrailsWe create a system message that clearly defines:1. The role of the assistant2. What it is allowed to do3. What it must refuse to do### Example system message:> “You are a finance education assistant. Your job is to help students understand finance concepts for exams. If a user asks for real-world financial or investment advice, politely refuse and explain that you cannot provide such advice.”This acts like a **rulebook** for the model.

#Practice
# **Utilizing systems messages**The Chat Completions endpoint supports three different roles to shape the messages sent to the model:- **System**: controls assistant's *behavior*- **User**: *instruct* the assistant- **Assistant**: *response* to user instruction


import os
from dotenv import load_dotenv
from openai import OpenAI

#load the environment variable
load_dotenv()

#Get & initialize the environment variable
api_key = os.getenv('OPENAI_API_KEY')

#Get & catch api_key load error
if not api_key:
    raise ValueError('API key not found/loaded: Please check enivronment file (.env)')

#Create OpenAI client
client = OpenAI(api_key=api_key)



# response = client.chat.completions.create(
#     model='gpt-4o-mini',
#     max_completion_tokens=150,
#     messages=[
#     {"role":"system",
#      "content": "You are a study planning assistant that creates plans for learning new skills."},
#     {"role": "user",
#      "content": "I want to learn to speak Dutch."}
#     ]
# )

# print(response.choices[0].message.content)


# **Adding guardrails**One of the most popular uses of system messages is to add ***guardrails***, which places restrictions on model outputs.

sys_msg = """You are a study planning assistant that creates plans for learning new skills.

If these skills are non related to languages, return the message:

'Apologies, to focus on languages, we no longer create learning plans on other topics.'
"""

# Create a request to the Chat Completions endpoint
response = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
    {"role": "system", "content": sys_msg},
    {"role": "user", "content": "Help me learn to Portuguese."}
  ]
)

print(response.choices[0].message.content)
